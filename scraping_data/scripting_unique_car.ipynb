{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corolla DX ABS ទឹមរៀបចំហើយថ្មីៗ 3000  Cars and Vehicles Cars for Sale Toyota Corolla 1996 Plate Number Used ('NaN',) ('NaN',) Auto Gold ឡានស្អាតមុខក្រោយអត់បុកអត់ប៉ះ ម៉ាសុីនប្រអប់លេខអេម\n",
      "Highlander 2005 V 4 ប៉ុង១ អត់បុក ខ្ចី 15800 11648490 Cars for Sale Toyota Highlander 2005 Plate Number Used ('NaN',) Petrol Auto Silver ឡានស្អាត អត់បុក កង់ថ្មី\n",
      "camry99Le abs ឡានស្អាត លេងយ៉ានគុជលក់ 4600$$ 4600  Cars and Vehicles Cars for Sale Toyota Camry 1999 Tax Paper New ('NaN',) Petrol Auto Black camry99Le abs ឡានស្អាត 4600$\n",
      "✅Camry LE05ABS កៅឥចុចក្នុងលឿង 12000  Cars and Vehicles Cars for Sale Toyota Camry 2005 Plate Number New Sedan Diesel Auto White ✅Camry LE05ABS កៅឥចុចក្នុងលឿង\n",
      "✅បងប្អូនចង់បានឡានស្អាតយកទៅប្រើមិនខុសបំណងទេ\n",
      "✅ម្ចាស់ដើមទីមួយថ្មីណាស់ស្រុីនមួយជុំ\n",
      "✅ធានាអត់បុក អត់កាត់ត អត់ប្តូរពណ៍ អត់ច្រេះ\n",
      "✅ក្នុងក្រៅថ្មីបាតខ្ចីកង់យ៉ាន់ថ្មីៗពូកស្បែកហើយ\n",
      "✅ម៉ាសុីនប្រអប់លេខជើងក្រោមហាប់ល្អណាស់\n",
      "✅ឡានស្អាតលំដាប់ម៉េឡាន\n",
      "Toyota Alphard 26500 11614209 Cars for Sale Toyota Alphard 2010 Plate Number Used Sedan Petrol Auto Black ដំលៃចចារមេីលផ្ទល់ជាមួយម្ចាស់\n",
      "07 full option ឡានអត់បុក អត់ប៉ះ 10900  Cars and Vehicles Cars for Sale Toyota Prius 2007 Plate Number Used Sedan Petrol Auto Gray ឡានជិះផ្ទាល់ មកមុនបានមុន\n",
      "លក់TUNDRAឆ្នាំ07ប៉ុង2រំលោះសុតរឺប្តូរទ្បានបានគ្រប់ខេត្ត 13900 11668573 Cars for Sale Toyota Tundra 2007 Plate Number Used Pickup LPG Auto Silver លក់តម្លៃពិសេស​ ថ្ងៃនេះ​ TUNDRA​ឆ្នាំ07ប៉ុង2​ មានរំលោះសុត​ រឺប្តូរទ្បានបាន​ គ្រប់ខេត្ត.ធានា១ជុំអត់បុក អត់កាត់ត អត់ប្តូរពណ៍ ឯកសារគ្រប់ កាត់ឈ្មោះ បាន​ ម៉ាសុីស្ងាត់រត់ស្រួល សុី​តិច​ ប្រអប់លេខល្អ​ សំបកកង់ថ្មី​ ជើងក្រោមហាប់​ ក្នុងថ្មី​ ម្ចាស់ទី១\n",
      "Prius 2008 Full Turing 12900  Cars and Vehicles Cars for Sale Toyota Prius 2008 Tax Paper New Pickup LPG Auto Gold Prius 2009 Full Turing ក្រដាសពន្ធ​ \n",
      "ធានាម៉ាសុីន​ប្រអប់លេខ​អាគុយ​ABS​មួយខែពេញ​\n",
      "Camry 2007, hybrid full option បើកដំបូល 16200  Cars and Vehicles Cars for Sale Toyota Camry 2007 Plate Number New Other Petrol Auto White ឡានលក់ Toyota Camry years 2007, hybrid Full Option បើកដំបូល ទឹកថ្នាំសុីន អត់បុក100% នៅអាគុយABs នៅល្អ ប្រញប់លុយ\n",
      "Toyota Prius 2010 Opt4 Sola តំលៃចចារបាន 20500 11667133 Cars for Sale Toyota Prius 2010 Tax Paper New Hatchback Hybrid Auto White 💥រៀបចំហើយរួចរាល់ សម្រស់មិនធម្មតា\n",
      "🚘 #Prius_010_Opt4_Solar ហ្សុីម៉ាជុំ\n",
      "👉តំលៃពិសេស 20,500$ចរចារ\n",
      "✅ធានាម៉ាសុីន+ប្រអប់លេខ1ខែ\n",
      "✅ធានាអាគុយHybrid+ABS+ប៊ូមទឹក+ប្រព័ន្ធភ្លើង1ខែ\n",
      "👉ទំនាក់ទំនងតាមរយៈលេខ\n",
      "☎️093477xxxClick To Call (ប្រព័ន្ធSmart)\n",
      "☎️089477xxxClick To Call (ប្រព័ន្ធCellcard)\n",
      "☎️067477xxxClick To Call (ប្រព័ន្ធ097)\n",
      "📥Telegram https://t.me/Kavdyseller777\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import cloudscraper\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# attribute\n",
    "list = ['Car_id', 'Title', 'Category', 'Brand', 'Model', 'Year', 'Tax_type', 'Condition', 'Body_type', 'Fuel', 'Transmission', 'Color', 'Location', 'Other']\n",
    "Car_id = \"NaN\",\n",
    "Title = \"NaN\",\n",
    "Category = \"NaN\",\n",
    "Brand = \"NaN\",\n",
    "Model = \"NaN\",\n",
    "Year = \"NaN\",\n",
    "Tax_type = \"NaN\",\n",
    "Condition = \"NaN\",\n",
    "Body_type = \"NaN\",\n",
    "Fuel = \"NaN\",\n",
    "Transmission = \"NaN\",\n",
    "Color = \"NaN\",\n",
    "Location = \"NaN\"\n",
    "other = \"NaN\"\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "file_path = 'khmer24_cars.json'\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "i = 0\n",
    "for car in data:\n",
    "    i += 1\n",
    "    if(i>10): break\n",
    "    # Initialize the scraper\n",
    "    scraper = cloudscraper.create_scraper()\n",
    "\n",
    "    # print(car[1])\n",
    "    url = 'https://www.khmer24.com' + car[1]\n",
    "    # url = 'https://www.khmer24.com/%E1%9E%9A%E1%9E%99%E1%9E%93%E1%9F%92%E1%9E%8F%E1%9E%9B%E1%9E%80%E1%9F%8B%E2%80%8B-%E1%9E%98%E1%9F%92%E1%9E%85%E1%9E%B6%E1%9E%9F%E1%9F%8B%E2%80%8B%E1%9E%8A%E1%9F%81%E1%9E%B8%E1%9E%98%E2%80%8B-ford-ecosport-2019-full%E2%80%8B-%E1%9E%91%E1%9E%B9%E1%9E%80%E1%9E%90%E1%9F%92%E1%9E%93%E1%9E%B6%E1%9F%86%E2%80%8B%E1%9E%A0%E1%9F%92%E1%9E%9F%E1%9E%BB%E1%9E%B8%E1%9E%93%E1%9E%98%E1%9E%BD%E1%9E%99%E1%9E%87%E1%9E%BB%E1%9F%86-adid-11606644'\n",
    "    response = scraper.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # name\n",
    "    name = soup.find('h1', class_='font_19 m-0 font_light_bold line_height_1_8 break_word_').text\n",
    "    \n",
    "    # price\n",
    "    price = str(soup.find('strong', class_='d-big-price').text).replace(',','').replace('$','')\n",
    "    \n",
    "    # car Id\n",
    "    car_ID = str(soup.find('div', class_='show_short_detail_post').find('dl').text).split(':')[-1]\n",
    "\n",
    "    # car info\n",
    "    car_infos = soup.find('div', class_='show_short_detail_post').findAll('div')\n",
    "    \n",
    "    # Categeory, Brand, Model, Year, Tax_type, Condition, Body_type, Fuel, Transmission, Color\n",
    "    # print(Categeory)\n",
    "    \n",
    "    for car in car_infos:\n",
    "        info = car.text.split(':')\n",
    "        attr = info[0].strip()\n",
    "        value = info[1].strip()\n",
    "        \n",
    "        if(attr == 'Category'):\n",
    "            Category = value\n",
    "        elif(attr == 'Brand'):\n",
    "            Brand = value\n",
    "        elif(attr == 'Model'):\n",
    "            Model = value\n",
    "        elif(attr == 'Year'):\n",
    "            Year = value\n",
    "        elif(attr == 'Tax Type'):\n",
    "            Tax_type = value\n",
    "        elif(attr == 'Condition'):\n",
    "            Condition = value\n",
    "        elif(attr == 'Body Type'):\n",
    "            Body_type = value\n",
    "        elif(attr == 'Fuel'):\n",
    "            Fuel = value\n",
    "        elif(attr == 'Transmission'):\n",
    "            Transmission = value\n",
    "        elif(attr == 'Color'):\n",
    "            Color = value\n",
    "        \n",
    "        # print(f'{attr}: {value}')\n",
    "        # infos.append(car.text.split(':')[-1].strip())\n",
    "    \n",
    "\n",
    "    other = soup.find('p', class_='mb-3 font_16 m-0 line_paragraph').text\n",
    "    print(name, price, car_ID, Category, Brand, Model, Year, Tax_type, Condition, Body_type, Fuel, Transmission, Color, other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Kamboul, Phnom Penh\n",
      " Preaek Pnov, Phnom Penh\n",
      " Ruessei Kaev, Phnom Penh\n",
      " Kamboul, Phnom Penh\n",
      " Ruessei Kaev, Phnom Penh\n",
      " Kamboul, Phnom Penh\n",
      " Ruessei Kaev, Phnom Penh\n",
      " Ruessei Kaev, Phnom Penh\n",
      " Kamboul, Phnom Penh\n",
      " Ruessei Kaev, Phnom Penh\n",
      " Kamboul, Phnom Penh\n",
      " Kamboul, Phnom Penh\n",
      " Ruessei Kaev, Phnom Penh\n",
      " Ruessei Kaev, Phnom Penh\n",
      " Kamboul, Phnom Penh\n",
      " Kamboul, Phnom Penh\n",
      " Ruessei Kaev, Phnom Penh\n",
      " Ruessei Kaev, Phnom Penh\n",
      " Kamboul, Phnom Penh\n",
      " Kamboul, Phnom Penh\n",
      " Kamboul, Phnom Penh\n",
      " Ruessei Kaev, Phnom Penh\n",
      " Kamboul, Phnom Penh\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.khmer24.com/c-cars-for-sale?keyword=&ad_field=toyota'\n",
    "cars = soup.find_all('div', class_='list_items_post')  # Adjust class name if needed\n",
    "for car in cars:\n",
    "    try:\n",
    "        name_tag = car.find('a', class_='position_relative d_block')\n",
    "        location = str(car.find('p', class_='truncate gr-p-date-loc').text).split('•')[-1]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    \n",
    "\n",
    "    # Add new job listings to the set\n",
    "    # for job in jobs:\n",
    "    #     try:\n",
    "    #         name_tag = job.find('a', class_='position_relative d_block')  # Adjust class name\n",
    "    #         if name_tag and name_tag.has_attr('href'):\n",
    "    #             job_name = name_tag.text.strip()\n",
    "    #             job_link = name_tag['href']\n",
    "    #             job_entry = (job_name, job_link)\n",
    "    #             unique_jobs.add(job_entry)\n",
    "    #     except Exception as e:\n",
    "    #         print(f\"Error processing job: {e}\")\n",
    "    #         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to khmer24_jobs.csv successfully.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Sample data (from JSON or other sources)\n",
    "data = [\n",
    "    {\"name\": \"Toyota Camry\", \"link\": \"https://www.khmer24.com/camry1\"},\n",
    "    {\"name\": \"Toyota Prius\", \"link\": \"https://www.khmer24.com/prius2\"}\n",
    "]\n",
    "\n",
    "# Specify the CSV file name\n",
    "csv_file = 'khmer24_jobs.csv'\n",
    "\n",
    "# Write the data to the CSV file\n",
    "with open(csv_file, 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"name\", \"link\"])\n",
    "    \n",
    "    # Write the header (column names)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    # Write the rows\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"Data written to {csv_file} successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/corolla-dx-abs-%E1%9E%91%E1%9E%B9%E1%9E%98%E1%9E%9A%E1%9F%80%E1%9E%94%E1%9E%85%E1%9F%86%E1%9E%A0%E1%9E%BE%E1%9E%99%E1%9E%90%E1%9F%92%E1%9E%98%E1%9E%B8%E1%9F%97-adid-11667640\n",
      "<dl><dt>Main Category : </dt><dd class=\"ms-1\">Cars and Vehicles</dd></dl>\n",
      "/highlander-2005-v-4-%E1%9E%94%E1%9F%89%E1%9E%BB%E1%9E%84%E1%9F%A1-%E1%9E%A2%E1%9E%8F%E1%9F%8B%E1%9E%94%E1%9E%BB%E1%9E%80-%E1%9E%81%E1%9F%92%E1%9E%85%E1%9E%B8-adid-11648490\n",
      "<dl><dt>Main Category : </dt><dd class=\"ms-1\">Cars and Vehicles</dd></dl>\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import cloudscraper\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define CSV file path\n",
    "csv_file = 'khmer24_cars.csv'\n",
    "\n",
    "# Write the header only if the file doesn't exist\n",
    "try:\n",
    "    with open(csv_file, 'x', newline='', encoding='utf-8-sig') as f:  # Use utf-8-sig for better Excel compatibility\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Car ID', 'Title', 'Price', 'Category', 'Brand', 'Model', 'Year', 'Tax Type', \n",
    "                         'Condition', 'Body Type', 'Fuel', 'Transmission', 'Color', 'city', 'district'])\n",
    "except FileExistsError:\n",
    "    pass  # File already exists, so we won't write the header again\n",
    "\n",
    "# Load car URLs from JSON\n",
    "file_path = 'khmer24_cars.json'\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Process each car URL\n",
    "i = 0\n",
    "for car in data:\n",
    "    i += 1\n",
    "    if i > 2:  # Limit to 10 entries for demonstration\n",
    "        break\n",
    "\n",
    "    # Initialize the scraper\n",
    "    scraper = cloudscraper.create_scraper()\n",
    "\n",
    "    # Get the car details page URL\n",
    "    url = 'https://www.khmer24.com' + car[1]\n",
    "    response = scraper.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Extract details\n",
    "    try:\n",
    "        # Location\n",
    "        provice = car[2].split(',')[0].strip()\n",
    "        district = car[2].split(',')[1].strip()        \n",
    "\n",
    "\n",
    "        # Name\n",
    "        name = soup.find('h1', class_='font_19 m-0 font_light_bold line_height_1_8 break_word_').text.strip()\n",
    "\n",
    "        # Price\n",
    "        price = str(soup.find('strong', class_='d-big-price').text).replace(',', '').replace('$', '').strip()\n",
    "\n",
    "        # Car ID\n",
    "        # car_ID = str(soup.find('div', class_='show_short_detail_post').find('dl').find('dd'))\n",
    "        car_ID = str(soup.find('div', class_='show_short_detail_post').find('dl'))\n",
    "        print(car[1])\n",
    "        print(car_ID)\n",
    "        # Car info\n",
    "        car_infos = soup.find('div', class_='show_short_detail_post').findAll('div')\n",
    "\n",
    "        # Initialize attributes\n",
    "        Category = Brand = Model = Year = Tax_type = Condition = Body_type = Fuel = Transmission = Color = \"NaN\"\n",
    "\n",
    "        for car_info in car_infos:\n",
    "            info = car_info.text.split(':')\n",
    "            attr = info[0].strip()\n",
    "            value = info[1].strip()\n",
    "\n",
    "            if attr == 'Category':\n",
    "                Category = value\n",
    "            elif attr == 'Brand':\n",
    "                Brand = value\n",
    "            elif attr == 'Model':\n",
    "                Model = value\n",
    "            elif attr == 'Year':\n",
    "                Year = value\n",
    "            elif attr == 'Tax Type':\n",
    "                Tax_type = value\n",
    "            elif attr == 'Condition':\n",
    "                Condition = value\n",
    "            elif attr == 'Body Type':\n",
    "                Body_type = value\n",
    "            elif attr == 'Fuel':\n",
    "                Fuel = value\n",
    "            elif attr == 'Transmission':\n",
    "                Transmission = value\n",
    "            elif attr == 'Color':\n",
    "                Color = value\n",
    "\n",
    "        # Other details\n",
    "        other = soup.find('p', class_='mb-3 font_16 m-0 line_paragraph').text.strip() if soup.find('p', class_='mb-3 font_16 m-0 line_paragraph') else \"NaN\"\n",
    "\n",
    "        # Append to CSV\n",
    "        # with open(csv_file, 'a', newline='', encoding='utf-8-sig') as f:  # Use utf-8-sig for Excel compatibility\n",
    "        #     writer = csv.writer(f)\n",
    "        #     writer.writerow([car_ID, name, price, Category, Brand, Model, Year, Tax_type, Condition,\n",
    "        #                      Body_type, Fuel, Transmission, Color, provice, district])\n",
    "\n",
    "        # print(f\"Appended: {name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing car: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
